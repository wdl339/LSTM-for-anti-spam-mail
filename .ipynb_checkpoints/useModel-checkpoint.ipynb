{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1078f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import tqdm\n",
    "import numpy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "from random import *\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "batch_size = 64\n",
    "src_vocab_size = 21128          # 字典大小\n",
    "d_model = 512                   # embedding维度\n",
    "num_layers = 2                  # LSTM层数\n",
    "hidden_size = 100               # LSTM隐藏层\n",
    "linear_hidden_size = 10         # 全链接层隐藏数\n",
    "classes = 2                     # 类别数\n",
    "dropout = 0.3                   # LSTM中dropout\n",
    "lr = 1e-3                       # 学习率\n",
    "epochs = 10                     # 训练次数   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2f915ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(myNet, self).__init__()\n",
    "        self.embed = torch.nn.Embedding(src_vocab_size, d_model)                        \n",
    "        self.lstm = torch.nn.LSTM(input_size=d_model, hidden_size=hidden_size,num_layers=num_layers,dropout=dropout)\n",
    "        self.linear = torch.nn.Linear(hidden_size, linear_hidden_size)\n",
    "        self.linear1 = torch.nn.Linear(linear_hidden_size, classes)\n",
    "    def forward(self,data):\n",
    "        x = self.embed(data)                             # [64,32,512]   把字用字向量表示\n",
    "        x,(h_n, c_n) = self.lstm(x.transpose(0, 1))      # x:[32, 64, 100]    记录每时刻最后一层的输出。\n",
    "                                                         # h_n: [2, 64, 100]  记录每一层最后一次的输出\n",
    "                                                         # c_n: [2, 64, 100]  记录每一层cell保存的值\n",
    "        x = self.linear(x[-1])                           # [64, 10] 经过第一层全连接层\n",
    "        x = self.linear1(x)                              # [64, 2] 经过第二层全连接层\n",
    "        return x       \n",
    "\n",
    "model = myNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9016f55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed.weight : torch.Size([21128, 512])\n",
      "lstm.weight_ih_l0 : torch.Size([400, 512])\n",
      "lstm.weight_hh_l0 : torch.Size([400, 100])\n",
      "lstm.bias_ih_l0 : torch.Size([400])\n",
      "lstm.bias_hh_l0 : torch.Size([400])\n",
      "lstm.weight_ih_l1 : torch.Size([400, 100])\n",
      "lstm.weight_hh_l1 : torch.Size([400, 100])\n",
      "lstm.bias_ih_l1 : torch.Size([400])\n",
      "lstm.bias_hh_l1 : torch.Size([400])\n",
      "linear.weight : torch.Size([10, 100])\n",
      "linear.bias : torch.Size([10])\n",
      "linear1.weight : torch.Size([2, 10])\n",
      "linear1.bias : torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model.pt', map_location=torch.device('cpu')))\n",
    "for name, parameters in model.named_parameters():\n",
    "    print(name, ':', parameters.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae203119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openvino as ov\n",
    "ov_model = ov.convert_model('lstm_model.onnx')\n",
    "ov.save_model(ov_model, 'model.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cddd0b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.runtime import Core\n",
    "# 实例化Core对象\n",
    "core = Core() \n",
    "det_ov_model = core.read_model('model.xml')\n",
    "    \n",
    "net = core.compile_model(det_ov_model, device_name=\"AUTO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4d84b760",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21128it [00:00, 1513660.52it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 101,  113, 7270, 3309, 6411,  928, 1762, 3315, 2356,  868, 1392, 5102,\n",
       "         6598, 3419, 5466, 4917,  809, 1350, 1313, 4995,  510, 4277, 5023,  511,\n",
       "         4510, 6413, 8038,  122,  122,  125,  126,  122,  125,  122,  130,  122,\n",
       "          130,  129,    0, 3330,  836,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_size = 60\n",
    "with open(\"./vocab.txt\", 'r', encoding='UTF-8') as f:\n",
    "        idx2word = {idx: line.strip() for idx, line in  enumerate(tqdm.tqdm(f))}\n",
    "        word2idx = {idx2word[key]: key for key in  idx2word}\n",
    "content = '(长期诚信在本市作各类资格职称以及印章、牌等。电话：11451419198 李伟'\n",
    "token_ids = []\n",
    "token_ids.append (word2idx['[CLS]'])\n",
    "for key in content:\n",
    "    token_ids.append(word2idx.get(key, 0))\n",
    "seq_len = len(token_ids)\n",
    "mask = []\n",
    "if pad_size:\n",
    "    if seq_len < pad_size:\n",
    "        token_ids += ([0] * (pad_size - seq_len))\n",
    "    else:\n",
    "        token_ids = token_ids[:pad_size]\n",
    "        seq_len = pad_size\n",
    "content\n",
    "token_ids\n",
    "datain = torch.tensor(token_ids)\n",
    "datain = datain.unsqueeze(0)\n",
    "datain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a1bc8d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n",
      "tensor([[0.0863, 0.0268]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "start_time_torch = time.time()\n",
    "test_output = model(datain.to(device)) \n",
    "end_time_torch = time.time()\n",
    "\n",
    "inference_time_torch = end_time_torch - start_time_torch\n",
    "inference_speed_torch = 1 / inference_time_torch\n",
    "\n",
    "print(test_output.argmax(dim=1))\n",
    "print(test_output)\n",
    "\n",
    "print(\"使用PyTorch推理时间：\", inference_time_torch, \"秒\")\n",
    "print(\"使用PyTorch推理速度：\", inference_speed_torch, \"次/秒\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dc25d066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "output_node = net.outputs[0] \n",
    "ir = net.create_infer_request()\n",
    "outputs = ir.infer(datain)[output_node]\n",
    "print(outputs.argmax())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
